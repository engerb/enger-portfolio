Enger Bewza: Product Design
Defining new and emerging product experiences
View my work >


Robots that deliver your food
    Serve, the autonomous delivery rover that safely navigates sidewalks today delivering food from restaurants to your door. 
    2018 - Current
    View project >

The right size, from your phone
    Ever buy shoes online only to realize they don't fit? Ya, that sucks. Dr. Scholl's 3D and Wiivv are a _step_ in the right direction.
    2014 - 2018
    View project >


A few things I do
    UX / UI design
    UX and logic flows, such as checkout, shipment tracking and other transactional flows. 
    Testing and iteration for increasing conversions.
    Creating web and native app comps and documentation for dev handoff. 
    Creating and maintaining design systems. 

    Physical product and CMF
    Prototypes using laser cutting and 3D printing, such as our rovers food storage.
    CMF including concepts, renders and final manufacturability. 
    Product packaging and out-of-box experience. 

    Dev work
    Web-dev work such as React for this website, the touch screen on our robot and Web-GL too. 
    Servers and signal processing in python, currently learning Tensor-flow.
    C / C++ on embedded systems as well as CUDA. 
    All helpful in building prototypes, some even work their way into our end products. 


Footer:
    [Photo of Enger]
    Hello! Thanks for checking out my work! 

    I'm a product designer who loves going out of my comfort zone to design new and exciting user-experiences. I started out making games and websites in 2006, went to school for 3D animation, and then took an internship in 2011 creating product prototypes with 3D printing. Now I'm working on an autonomous delivery robot and all the machine learning and user challenges around that.

    I'm passionate in working on the most challenging and undefined products, with cool people smarter than me.

    Resume | Linkedin | Github | Codepen | Behance



-------------------------------------------------------------------------


Delivery robot
    Serve: The autonomous delivery rover.
    Safely navigates sidewalks today delivering food from restaurants to your door.

    Postmates - X Team
    2018 - Current

    Categories:
    UX/UI design, Dev, CMF, Prototyping

    Tools used:
    Figma, Sketch, Invision studio, Blender 3D, Adobe Ps/Ai/Ae/Pr/Au, Laser cutter, 3D printers, C/C++, JS, Python

    Reading time:
    15 minutes / 5 minutes quickread


    Challenges
        "I don't wan't some robot taking my job!"
        "Robots are not there yet, I don't feel safe around one."
        "Scooters and other crap already litter the sidewalk, we don't need more crap!"
        "Why should I have to move out the way for some stupid tech company?"
        "Tech companies run rampant and are out of touch with how their actions affect us"
        "What about people in wheelchairs?"
    
    Initial concept
        In 2018, I joined up with the X-team at Postmates, the goal being to start a design team and bring a product mindset to an engineering dominated space. < Up to that point, there were rovers that were operating, but very simple and a bit scary. 

        Robotic companies at the time were either very engineering driven resulting in very unapproachable and scary products, or more cheerful, but not so useful toys. > <- It was my job to take threatening robots and turn it into something people would want to see on sidewalks.

        [ Collage of existing robots with some "quote" notes of feedback on them ]

        NDD did our initial concepts, and this is when I came on. Through meeting restaurants who use the Postmates platform, doing actual deliveries to meet end-users, and surveys of existing robots, we were able to put together a list of requirements for what we would want to create for autonomous food delivery. 
    
    Product requirements
        - Friendly and approachable
        - Able to communicate intent
        - People should feel safe around it
        - Secure and hygienic, yet easy to transact with
        - Recognizable, not just some robot

        A few things I pushed for personally were a touch screen because going into restaurants, I saw that they had 10 tablets, and they are not going unplug tablets and walk outside with them to unlock the rover. Another thing I felt was important was that it should have 4 wheels and steer like a car, not 6 and like a tank, this would allow the rover to communicate it's intended direction of travel. <- simplify as people don't really understand the whole tablets or problem thing, or maybe some picture / graphic

        [ Concepts ]

    Inception of Serve
        After testing these concepts through the use of online surveys and out-in-the-wild cardboard model testing, we landed on Serve. Most people understood where the front was, it's face, and how to intuitively interact with it. 

        [ Concept of Serve ]

        Now that we had our product's concept, we needed to get to work on detailing all the interactions Serve may have with the humans.

    Communication challenges, the "sidewalk UI"
        We found the large majority of interactions would be with random people on the sidewalks and with cars at intersections. Pedestrians don't know how to, nor want to interact with a sidewalk robot. This means we must make these brief interactions seamless and pleasurable, paying particular attention to public acceptance and safety. 

        We were essentially designing the sidewalk-UI, a similar concept to what Ford and Audi were attempting in their AV research. In those 3 seconds someone looks up from their phone and passes the robot, it needs to be safe, understandable, and they need to leave that interaction feeling like their space and agency was not violated. 

        That means that we needed to use Serve lights, sounds, and motion to communicate that Serve has a purpose, while still being cheerful and intuitive.

        Communication through lights
            I started with a journey map of public interactions and end-to-end customer flows. This helped us enumerate every possible interaction we'd need to account for and design around.

            For the eyes and strip, I got to work soldering on a hardware prototype. To create animations for this hardware, I put together a C library that translated and played 2D animations that I created via Photoshop and a Python script. For a full vision of the end product, I also implemented these animations onto a 3D render created in Blender.

            [ Video and pics of Serve prototype hardware ]

            We then put this all together into a test rig that we remotely operated through the busiest streets of Vancouver.

            Here's some key learnings:
                - No lights left people confused, thought it was rolling on it's own, broken.
                - Lights produced a much more positive reaction, leaving people delighted instead of annoyed. 

            [ video or pic of Serve prototype ]

            Later on, Ken Kocienda, one of the engineers on the first iPhone, joined our design team and put our LED expression system on steroids. This allowed me to focus on designs while he focused on the implementation. 

            [ Video of Ai Chechni and serve eyes ]

        Communication through sounds
            Sound design is hard.. we brought in a contractor with experience in sound branding as well as vehicles such as Telsa to help help Serve communicate through sound. We created a list of situations and transactions that we would need sounds for and I worked as a project manager to make sure we were successful in meeting out goals. 

            It was a challenge to try to find Serve's voice, this ended up taking a few months of back and forth to finally get to something we all felt sounded like Serve. 

            We made the decision to never have Serve "speak" with real words, as that would promise some kind of awkward vocal interaction (as detailed in this paper) and instead should make "voice" intonations similar to how R2D2 might communicate.

            [ Some kind of graphic for sound or the sound layers ]

            Since Serve was an electric vehicle that made no natural noise, I also wanted Serve to communicate it's speed. This is something that most EV's are required to do <link> today, and is important for Safety so that people are aware "something" is approaching behind them, coming around a corner, or increasing / decreasing in speed. 

            To achieve this, we worked with our sound designer to find the right sound and concept for modulating it, then I wrote a python script that would take Serves speed and modulate a sound sample in real time. This sound modulates it's pitch on speed and volume based on accelerations curves. 

            [ Video of Serve with running sound ] 

        Communication through motion
            How Serve moves communicates a lot! While watching our older rovers drive, their jitteriness and indecisiveness, even in the slightest, would cause an oncoming pedestrian to walk around our rover in the road. This was embarrassing and was the ultimate failure. 
            
            Serve only having 4 wheals instead of the common 6 wheel configuration as well as being able to steer like a car were two huge steps in the direction of empowering a pedestrian to feel like they can be safe, respected and their space not infringed on. Even though serve was also capable of tank style skid steering, we advised that only real steering be used because as soon as Serve breaks from it's understood motion capabilities, that level of understanding and trust we could have built is destroyed. 

            [ Animated graphic of steering and motion paths ]

            I also chose the most difficult situation to try and solve: A large group of people blocking Serves path. I came up with the initial idea visiting the California Academy of Sciences in the Golden Gate Park one busy weekend; It was extremely busy and I watched a mother pushing her stroller through a large crowd of people, while texting. Never once did she stop the stroller completely, she kept it moving, even slowly, and successfully was able to "cut" through the crowd without eye contact or saying anything. 

            I applied this as a first iteration for how Serve would be able to keep moving. Once Serve stops, no matter how many sounds it makes, people would seem to think it was there for them and trying to instead interact with it. Slight movement and steering allowed Serve to communicate it's intent.

            [ Graphic of Serve moving through crowd ]
        
    Transactional design: How to interact with Serve
        When Serve get's to a restaurant or to the end-user who placed their order, we enter the transactional part of the experience. The end-user has already ordered and payed using the Postmates App, the merchant has already received the order too. And the end-user / merchant are already notified that Serve will be coming, and neither has opted out of this due to a disability or other reasons; We just need the merchant to be able to easily load and secure the food, and the end-user to be able to retrieve their food.

        [ Maybe some graphics on people loading Serve or instagram videos ]

        I created a web-app and Serve lid prototype that would allow me to test with users and iterate on the design. The goals being for people to understand that they need to enter the order number, that the lid is going to open, and that the lid is going to close and lock. I also wanted merchants to be able to close it so they could go grab more items and come back. 

        [ prototype and webflow ]

        I landed on a strip animation that would show success and created a screen library in JS that's running on the rover today. The animations on the strip and screen give a quick preview of what the lid is going to do so that people get their hands out of the way or remove any items they left on-top. This was combined with sounds from our sound designer that created an easy to understand and low-friction experience that tested well wit users. 

        [ some sizzle on the transactional flow ]

    Food storage in Serve
        Our initial food storage in Serve was a flex-able insolation liner with a grate and cupholders in the bottom. With our more recent design, we had a lot more space to work with. 

        [ side by side drawing of old vs new serve cargo and maybe an current cargo insert ] 

        For our latest revision on the cargo, we wanted to satisfy a few things:
            - No moving parts or modularity.
                Merchants should open Serve and thrown things in as fast as possible, they don't have time to figure out bungie cords and fold-out cupholders.
            - Easily cleanable
                The older liner was hard to clean when something spilled, and the last thing you want to see when getting your food is old food debres or smell. 
            - Safely hold different types of food and drinks
                We didn't want drinks spilling or food moving around too much, but also enough space for things like pizza boxes. 

        I created a few configurations in Blender that we measured with a few many food items, pizza boxes and beverage cups. We gauged the average orders with the vast amount of order data to come up with what we felt was the most optimal configurations. 

        I then laser cut and 3D printed some fo these configurations for use to test. 

        [ renders and images of laser cut and 3D prints ]

        The one that test best was 2 cupholders and an offset pizza shelf design. The allowed many different types of order combinations to fit and not move around too much during a delivery.

    CMF - Serve's style
        ...
        The goals of Serve's "colour, material and finish" are as follow:
            - Cheerful and fun 
            - Not another robo-cop
            - Not just some stark white robot
            - Recognizable, establishing a brand

        I created a template file that allowed me to create design concepts, narrow down different vinyl wraps, and also create designs around the limitations of other manufacturing methods for us to explore. 


    Remote tele-operation
        ... (comb the phantom article)
        Sidewalks don't have lanes, pedestrian behavior is not as black and white as the rules of the road. As autonomy improves and we teach Serve how to navigate every new situations we enumerate, it makes sense that we can monitor Serve and make sure everything is safe and running smoothly. Our tele-ops interface allows operators to monitor and intervene if necessary. 

        [ Allen looking at a monitor ]

        My initial designs were based out camera projections onto lidar data to create a 3rd person perspective--much like how BMW or some other brands does well, but this was too far out of the execution zone so I scaled back and refocused on these requirements:
            - Be able to monitor multiple rovers at once
            - Scalable to a queue based intervention system
            - Understand what the rover is going to do next so that you can focus on others instead of trying to guess what the rover will do next. 
            - Understand what state of a job the rover is in

        
        Motion path
        ...

        State gem 
        ... 

        Job states
        [older design]
        [why it changed]

    Asking for permission instead of forgiveness
        Do you think if Uber or Lyft, when they were first starting asked each city for permission and permits, if they would have been as successful as they are today? Well, It's not 2010, and people today are more pessimistic towards tech than ever these days. Instead of unleashing Serve onto the streets of LA (And SF for testing), we instead went to the city council and asked for permits, and we had strategies and answers to the hard questions around labour, disabilities and safety. 

        We ran small studies with people in wheelchairs, blind and deaf and incorporated their feedback into how Serve moves, and how it communicates. 

        We also prepped lots of material on how Serve sees and safely navigates the world. 

        We also modeled how Serve would take short walking distance jobs, usually the less preferred ones that a currier would have to do. 

        It was difficult and slow, but we got the permits finally. 


    
    Essential services
        During the COVID-19 outbreak, we were ruled an essential service and cities and detractors on social media changed their tone from: "Who needs some dumb robot?" to "Contactless robot delivery makes so much sense". Cities and districts that were slow to respond and bureaucratic with permits instead reached out and granted permits immediately. 

        One thing we used to reduce exposure during this time was to automatically open the lid when a merchant approached, and same for the end-user. It's obviously not as secure but much less people are out so it was not difficult. 

    
    How people respond - Social media
        [ collage of people going nuts from tic-tok / insta ]


    





